{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PartidaID', 'Partida', 'FechaInicio', 'Agrupacion', 'ZonaPesca',\n",
       "       'Proveedor', 'Origen', 'Lomera', 'MP', 'TipoMP', 'NombreMP',\n",
       "       'EspecieMP', 'TipoCodeMP', 'Peque√±oMP', 'VentrescaMP', 'PlantaMP',\n",
       "       'PesoMedio', 'PesoPartida', 'PesoVersiones', 'MinutosPelado',\n",
       "       'PesoPales', 'RtoLimpieza', 'MinutosPersonaKg', 'DiasFrigorifico',\n",
       "       'ZonaFAO', 'Sal', 'Histamina', 'Mercurio', 'Oxidacion', 'Rechazo',\n",
       "       'Rechazos', 'TipoPesca', 'Carguero'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "\n",
    "def get_root_path():\n",
    "    cwd = os.getcwd()\n",
    "    while str(os.getcwd()).split('\\\\')[-1] != 'JealsaML':\n",
    "        os.chdir(\"..\")\n",
    "        cwd = os.getcwd()\n",
    "    return cwd\n",
    "\n",
    "ROOT_DIR = get_root_path()\n",
    "\n",
    "sys.path.insert(0, ROOT_DIR)\n",
    "\n",
    "from src.models.utils import fit_model\n",
    "\n",
    "# Paths de datos\n",
    "mypath = os.path.join(ROOT_DIR, 'data\\\\clean\\\\Pequeno.csv')         # Origen\n",
    "\n",
    "# Dataframe principal de Partidas\n",
    "dtypes = {'Partida':str,\n",
    "          'Agrupacion':str,\n",
    "          'MP':str}\n",
    "\n",
    "dates = ['FechaInicio']\n",
    "df = pd.read_csv(mypath, dtype=dtypes, parse_dates=dates)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "#from keras.layers.core import Dense, Dropout\n",
    "#from keras.models import Sequential\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils para src/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def k_fold_cross_validation(items, k, randomize=False):\n",
    "\n",
    "    if randomize:\n",
    "        items = list(items)\n",
    "        shuffle(items)\n",
    "\n",
    "    slices = [items[i::k] for i in range(k)]\n",
    "\n",
    "    for i in range(k):\n",
    "        validation = slices[i]\n",
    "        training = [item\n",
    "                    for s in slices if s is not validation\n",
    "                    for item in s]\n",
    "        yield training, validation\n",
    "        \n",
    "\n",
    "def split_data_by_index(df, train_idx, test_idx, target):\n",
    "    \"\"\"\n",
    "    A partir de un df divide obtiene las matrices numpy\n",
    "    X_train, X_test, y_train, y_test segun unos indices y \n",
    "    una variable target\n",
    "    \"\"\"\n",
    "    # Preparamos los datos de entrada en los modelos\n",
    "    df_train, df_test = data_ml.ix[train_idx], data_ml.ix[test_idx]\n",
    "        \n",
    "    # Convertimos features y target en numpies\n",
    "    X_train = np.array(df_train.drop(columns=[target], axis= 1))\n",
    "    X_test = np.array(df_test.drop(columns=[target], axis= 1))\n",
    "    y_train = np.array(df_train[target])\n",
    "    y_test = np.array(df_test[target])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "def fit_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fita un modelo de regresion a partir de unos datos:\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    err_train = get_error(y_train, model.predict(X_train))\n",
    "    err_test = get_error(y_test, y_pred)\n",
    "\n",
    "    return model, y_pred, err_train, err_test\n",
    "\n",
    "\n",
    "def get_error(y_real, y_pred):\n",
    "    mae = mean_absolute_error(y_real, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_real, y_pred))\n",
    "    r2 = r2_score(y_real, y_pred)\n",
    "    \n",
    "    return [mae, rmse, r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 1 - Variables antiguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DiasFrigorifico</th>\n",
       "      <th>Sal</th>\n",
       "      <th>Histamina</th>\n",
       "      <th>PesoMedio</th>\n",
       "      <th>MinutosPersonaKg</th>\n",
       "      <th>RtoLimpieza</th>\n",
       "      <th>ZonaPesca_Atlantico</th>\n",
       "      <th>ZonaPesca_Indico</th>\n",
       "      <th>EspecieMP_BI</th>\n",
       "      <th>EspecieMP_SK</th>\n",
       "      <th>EspecieMP_YF</th>\n",
       "      <th>TipoPesca_FAD_FREE</th>\n",
       "      <th>TipoPesca_LINE_MSC</th>\n",
       "      <th>TipoPesca_MSC</th>\n",
       "      <th>TipoPesca_POLE_LINE</th>\n",
       "      <th>TipoPesca_STANDARD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.152331</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.711085</td>\n",
       "      <td>3.073936</td>\n",
       "      <td>1.592539</td>\n",
       "      <td>40.712205</td>\n",
       "      <td>0.358108</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>0.180743</td>\n",
       "      <td>0.535473</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.839527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.226622</td>\n",
       "      <td>0.480656</td>\n",
       "      <td>4.070795</td>\n",
       "      <td>1.079419</td>\n",
       "      <td>0.386625</td>\n",
       "      <td>3.261236</td>\n",
       "      <td>0.479850</td>\n",
       "      <td>0.479850</td>\n",
       "      <td>0.385131</td>\n",
       "      <td>0.499162</td>\n",
       "      <td>0.451214</td>\n",
       "      <td>0.122462</td>\n",
       "      <td>0.162299</td>\n",
       "      <td>0.081991</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.367355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.307582</td>\n",
       "      <td>2.850972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.550556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>1.335466</td>\n",
       "      <td>39.551822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>1.504687</td>\n",
       "      <td>41.022675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119.500000</td>\n",
       "      <td>1.123929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>1.793675</td>\n",
       "      <td>42.314347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.000000</td>\n",
       "      <td>3.217500</td>\n",
       "      <td>56.946391</td>\n",
       "      <td>9.390000</td>\n",
       "      <td>2.957214</td>\n",
       "      <td>49.254630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DiasFrigorifico         Sal   Histamina   PesoMedio  MinutosPersonaKg  \\\n",
       "count       592.000000  592.000000  592.000000  592.000000        592.000000   \n",
       "mean         89.152331    0.848361    0.711085    3.073936          1.592539   \n",
       "std          72.226622    0.480656    4.070795    1.079419          0.386625   \n",
       "min           1.000000    0.000000    0.000000    1.080000          0.307582   \n",
       "25%          34.000000    0.550556    0.000000    2.460000          1.335466   \n",
       "50%          70.000000    0.912500    0.000000    2.860000          1.504687   \n",
       "75%         119.500000    1.123929    0.000000    3.380000          1.793675   \n",
       "max         359.000000    3.217500   56.946391    9.390000          2.957214   \n",
       "\n",
       "       RtoLimpieza  ZonaPesca_Atlantico  ZonaPesca_Indico  EspecieMP_BI  \\\n",
       "count   592.000000           592.000000        592.000000    592.000000   \n",
       "mean     40.712205             0.358108          0.641892      0.180743   \n",
       "std       3.261236             0.479850          0.479850      0.385131   \n",
       "min       2.850972             0.000000          0.000000      0.000000   \n",
       "25%      39.551822             0.000000          0.000000      0.000000   \n",
       "50%      41.022675             0.000000          1.000000      0.000000   \n",
       "75%      42.314347             1.000000          1.000000      0.000000   \n",
       "max      49.254630             1.000000          1.000000      1.000000   \n",
       "\n",
       "       EspecieMP_SK  EspecieMP_YF  TipoPesca_FAD_FREE  TipoPesca_LINE_MSC  \\\n",
       "count    592.000000    592.000000          592.000000          592.000000   \n",
       "mean       0.535473      0.283784            0.015203            0.027027   \n",
       "std        0.499162      0.451214            0.122462            0.162299   \n",
       "min        0.000000      0.000000            0.000000            0.000000   \n",
       "25%        0.000000      0.000000            0.000000            0.000000   \n",
       "50%        1.000000      0.000000            0.000000            0.000000   \n",
       "75%        1.000000      1.000000            0.000000            0.000000   \n",
       "max        1.000000      1.000000            1.000000            1.000000   \n",
       "\n",
       "       TipoPesca_MSC  TipoPesca_POLE_LINE  TipoPesca_STANDARD  \n",
       "count     592.000000           592.000000          592.000000  \n",
       "mean        0.006757             0.111486            0.839527  \n",
       "std         0.081991             0.315000            0.367355  \n",
       "min         0.000000             0.000000            0.000000  \n",
       "25%         0.000000             0.000000            1.000000  \n",
       "50%         0.000000             0.000000            1.000000  \n",
       "75%         0.000000             0.000000            1.000000  \n",
       "max         1.000000             1.000000            1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "## ROW SELECTION\n",
    "def drop_missings_peque√±o(df):\n",
    "    df = df.loc[~df.PesoPales.isna()]\n",
    "    df = df.loc[df.RtoLimpieza > 0.3]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = drop_missings_peque√±o(df)\n",
    "\n",
    "# Eliminamos datos del PAC\n",
    "df = df.loc[df.ZonaPesca != 'Pacifico']\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "## FEATURE SELECTION\n",
    "data_ml = df.loc[:,['ZonaPesca','EspecieMP','TipoPesca', 'DiasFrigorifico',\n",
    "                    'Sal','Histamina','PesoMedio','MinutosPersonaKg','RtoLimpieza']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## MISSING IMPUTATION\n",
    "data_ml = data_ml.fillna(0)\n",
    "\n",
    "## CATEGORICAL ENCODING\n",
    "data_ml = pd.get_dummies(data_ml).fillna(0)\n",
    "\n",
    "data_ml.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS\n",
    "\n",
    "# Definimos o scaler e os modelos\n",
    "scaler = ('scaler', MinMaxScaler())\n",
    "\n",
    "models = [('Ridge', ('RDG', Ridge(normalize=True))),\n",
    "          ('Lasso', ('LSS', Lasso()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.611077</td>\n",
       "      <td>2.966217</td>\n",
       "      <td>1.210496e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>1.829895</td>\n",
       "      <td>3.840129</td>\n",
       "      <td>6.892614e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.818424</td>\n",
       "      <td>3.163885</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>2.031028</td>\n",
       "      <td>4.002898</td>\n",
       "      <td>-1.167626e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.690258</td>\n",
       "      <td>3.161309</td>\n",
       "      <td>1.195944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>1.379943</td>\n",
       "      <td>1.889467</td>\n",
       "      <td>8.837794e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.892455</td>\n",
       "      <td>3.369191</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>1.502352</td>\n",
       "      <td>2.033190</td>\n",
       "      <td>-5.558257e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.587387</td>\n",
       "      <td>2.742703</td>\n",
       "      <td>1.417751e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>2.053858</td>\n",
       "      <td>5.135406</td>\n",
       "      <td>2.535301e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.821097</td>\n",
       "      <td>3.305226</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>2.205912</td>\n",
       "      <td>2.814995</td>\n",
       "      <td>-1.100826e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.670770</td>\n",
       "      <td>3.163799</td>\n",
       "      <td>1.128817e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>1.504292</td>\n",
       "      <td>1.889257</td>\n",
       "      <td>2.248586e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.865059</td>\n",
       "      <td>3.359063</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>1.673477</td>\n",
       "      <td>2.145857</td>\n",
       "      <td>-5.703717e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.691528</td>\n",
       "      <td>3.179343</td>\n",
       "      <td>1.141435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>1.367297</td>\n",
       "      <td>1.618812</td>\n",
       "      <td>2.165983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.890979</td>\n",
       "      <td>3.377969</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>1.489831</td>\n",
       "      <td>1.861748</td>\n",
       "      <td>-3.617591e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model    Set       MAE      RMSE            R2\n",
       "0   Ridge  train  1.611077  2.966217  1.210496e-01\n",
       "1   Ridge   test  1.829895  3.840129  6.892614e-02\n",
       "2   Lasso  train  1.818424  3.163885  0.000000e+00\n",
       "3   Lasso   test  2.031028  4.002898 -1.167626e-02\n",
       "4   Ridge  train  1.690258  3.161309  1.195944e-01\n",
       "5   Ridge   test  1.379943  1.889467  8.837794e-02\n",
       "6   Lasso  train  1.892455  3.369191  0.000000e+00\n",
       "7   Lasso   test  1.502352  2.033190 -5.558257e-02\n",
       "8   Ridge  train  1.587387  2.742703  1.417751e-01\n",
       "9   Ridge   test  2.053858  5.135406  2.535301e-02\n",
       "..    ...    ...       ...       ...           ...\n",
       "30  Lasso  train  1.821097  3.305226  0.000000e+00\n",
       "31  Lasso   test  2.205912  2.814995 -1.100826e-01\n",
       "32  Ridge  train  1.670770  3.163799  1.128817e-01\n",
       "33  Ridge   test  1.504292  1.889257  2.248586e-01\n",
       "34  Lasso  train  1.865059  3.359063  0.000000e+00\n",
       "35  Lasso   test  1.673477  2.145857 -5.703717e-07\n",
       "36  Ridge  train  1.691528  3.179343  1.141435e-01\n",
       "37  Ridge   test  1.367297  1.618812  2.165983e-01\n",
       "38  Lasso  train  1.890979  3.377969  0.000000e+00\n",
       "39  Lasso   test  1.489831  1.861748 -3.617591e-02\n",
       "\n",
       "[40 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FITTING\n",
    "\n",
    "# Cogemos los nombres de las variables para usarlos m√°s adelante\n",
    "features_list = data_ml.columns\n",
    "target = 'RtoLimpieza'\n",
    "\n",
    "\n",
    "def compare_regression_models_cv(df, models, target, scaler, k=10):\n",
    "    \"\"\"\n",
    "    Compara modelos de regresion por Cross Validation\n",
    "    \n",
    "    Devuelve un dataframe con los resultados MAE, RMSE y R2 por modelo y set (train/test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creamos la lista de items para poder seleccionar del indice\n",
    "    items = [i for i in range(df.shape[0])]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for train_idx, test_idx in k_fold_cross_validation(items, k=k, randomize=True):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_data_by_index(df, train_idx, test_idx, target)\n",
    "\n",
    "        for name, model in models:\n",
    "            pipeline = Pipeline(steps =[scaler,model])\n",
    "\n",
    "            # FITAMOS\n",
    "            _, _, err_train, err_test = fit_model(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "            # CARGAMOS RESULTADOS\n",
    "            results.append([name, \"train\"] + err_train)\n",
    "            results.append([name, \"test\"] + err_test)\n",
    "            \n",
    "    return pd.DataFrame(data = results, columns = ['Model', 'Set', 'MAE','RMSE','R2'])\n",
    "        \n",
    "compare_regression_models_cv(data_ml, models, target, scaler, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Set</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.644993</td>\n",
       "      <td>3.122968</td>\n",
       "      <td>0.125388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>test</td>\n",
       "      <td>1.755407</td>\n",
       "      <td>2.384857</td>\n",
       "      <td>-0.028441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>train</td>\n",
       "      <td>1.851283</td>\n",
       "      <td>3.339334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>test</td>\n",
       "      <td>1.893243</td>\n",
       "      <td>2.434762</td>\n",
       "      <td>-0.071934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>train</td>\n",
       "      <td>1.704967</td>\n",
       "      <td>3.188181</td>\n",
       "      <td>0.114483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model    Set       MAE      RMSE        R2\n",
       "0  Ridge  train  1.644993  3.122968  0.125388\n",
       "1  Ridge   test  1.755407  2.384857 -0.028441\n",
       "2  Lasso  train  1.851283  3.339334  0.000000\n",
       "3  Lasso   test  1.893243  2.434762 -0.071934\n",
       "4  Ridge  train  1.704967  3.188181  0.114483"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = \n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results_train ={}\n",
    "modelos = ['manual', 'ridge','lasso','cart','svr','xgb','rf', 'ann']\n",
    "for modelo in modelos:\n",
    "    results[modelo]=[]\n",
    "    results_train[modelo]=[]\n",
    "\n",
    "\n",
    "items = [i for i in range(data_ml.shape[0])]\n",
    "for training, validation in k_fold_cross_validation(items, 10):\n",
    "    \n",
    "    # Preparamos los datos de entrada en los modelos\n",
    "    df_train = data_ml.ix[training]\n",
    "    df_validation = data_ml.ix[validation]\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATOS PARA ML\n",
    "    #######################################################\n",
    "    \n",
    "    df_train_dummies = pd.get_dummies(df_train).fillna(0)\n",
    "    df_validation_dummies = pd.get_dummies(df_validation).fillna(0)\n",
    "    \n",
    "    # checkear que tengan las mismas columnas\n",
    "    for column in df_train_dummies.columns:\n",
    "        if column not in df_validation_dummies:\n",
    "            df_validation_dummies[column]=0\n",
    "    \n",
    "    features_list = df_train_dummies.columns\n",
    "    \n",
    "    # Convertimos features y target en numpies\n",
    "    X_train = np.array(df_train_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    X_test = np.array(df_validation_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    y_train = np.array(df_train_dummies['RtoLimpieza'])\n",
    "    y_test = np.array(df_validation_dummies['RtoLimpieza'])\n",
    "    \n",
    "    # Normalizamos los predictores\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xscaler.fit(X_train)\n",
    "    X_train = Xscaler.transform(X_train)\n",
    "    X_test = Xscaler.transform(X_test)\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RIDGE REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    ridge = Ridge(normalize=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge.predict(X_test)\n",
    "    results['ridge'].append(get_error(y_test, y_pred_ridge))\n",
    "    results_train['ridge'].append(get_error(y_train, ridge.predict(X_train)))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### LASSO REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_lasso = lasso.predict(X_test)\n",
    "    results['lasso'].append(get_error(y_test, y_pred_lasso))\n",
    "    results_train['lasso'].append(get_error(y_train, lasso.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### CART\n",
    "    #######################################################\n",
    "    \n",
    "    cart = DecisionTreeRegressor()\n",
    "    cart.fit(X_train, y_train)\n",
    "    y_pred_cart = cart.predict(X_test)\n",
    "    results['cart'].append(get_error(y_test, y_pred_cart))\n",
    "    results_train['cart'].append(get_error(y_train, cart.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### SVC REGRESOR\n",
    "    #######################################################\n",
    "    \n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred_svr = svr.predict(X_test)\n",
    "    results['svr'].append(get_error(y_test, y_pred_svr))\n",
    "    results_train['svr'].append(get_error(y_train, svr.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### XGB\n",
    "    #######################################################\n",
    "    \n",
    "    xgb = GradientBoostingRegressor()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    results['xgb'].append(get_error(y_test, y_pred_xgb))\n",
    "    results_train['xgb'].append(get_error(y_train, xgb.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RANDOM FOREST\n",
    "    #######################################################\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    results['rf'].append(get_error(y_test, y_pred_rf))\n",
    "    results_train['rf'].append(get_error(y_train, rf.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATA PREP FOR ANN\n",
    "    #######################################################\n",
    "    \"\"\"\n",
    "    yscaler = MinMaxScaler()\n",
    "    yscaler.fit(y_train.reshape(-1,1))\n",
    "    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\n",
    "    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN - MODEL CONSTRUCTION\n",
    "    #######################################################\n",
    "    \n",
    "    annmodel = Sequential()\n",
    "    annmodel.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    annmodel.add(Dropout(0.2))\n",
    "    annmodel.add(Dense(25, activation='relu'))\n",
    "    annmodel.add(Dense(1, activation = \"sigmoid\"))\n",
    "    annmodel.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN\n",
    "    #######################################################\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \n",
    "          validation_data = (X_test, y_test_ann))\n",
    "    y_pred_ann = annmodel.predict(X_test)\n",
    "    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\n",
    "    results['ann'].append(get_error(y_test, y_pred_ann_desnorm))\n",
    "    \n",
    "    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\n",
    "    results_train['ann'].append(get_error(y_train, y_pred_ann_train))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>3.132913</td>\n",
       "      <td>0.546874</td>\n",
       "      <td>4.894802</td>\n",
       "      <td>1.119125</td>\n",
       "      <td>0.216245</td>\n",
       "      <td>0.512191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.781429</td>\n",
       "      <td>0.583474</td>\n",
       "      <td>6.162906</td>\n",
       "      <td>2.047244</td>\n",
       "      <td>-0.018191</td>\n",
       "      <td>0.025826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>1.810579</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>2.654796</td>\n",
       "      <td>0.430105</td>\n",
       "      <td>0.609650</td>\n",
       "      <td>0.623526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.379359</td>\n",
       "      <td>0.538384</td>\n",
       "      <td>5.900599</td>\n",
       "      <td>2.038506</td>\n",
       "      <td>0.079525</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>1.384249</td>\n",
       "      <td>0.194915</td>\n",
       "      <td>1.965040</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>0.798501</td>\n",
       "      <td>0.270216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>1.356447</td>\n",
       "      <td>0.142933</td>\n",
       "      <td>1.936297</td>\n",
       "      <td>0.354708</td>\n",
       "      <td>0.811613</td>\n",
       "      <td>0.246810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mae_mean   mae_std  rmse_mean  rmse_std   r2_mean    r2_std\n",
       "0  manual       NaN       NaN        NaN       NaN       NaN       NaN\n",
       "1   ridge  3.132913  0.546874   4.894802  1.119125  0.216245  0.512191\n",
       "2   lasso  2.781429  0.583474   6.162906  2.047244 -0.018191  0.025826\n",
       "3    cart  1.810579  0.211867   2.654796  0.430105  0.609650  0.623526\n",
       "4     svr  2.379359  0.538384   5.900599  2.038506  0.079525  0.036457\n",
       "5     xgb  1.384249  0.194915   1.965040  0.450217  0.798501  0.270216\n",
       "6      rf  1.356447  0.142933   1.936297  0.354708  0.811613  0.246810\n",
       "7     ann       NaN       NaN        NaN       NaN       NaN       NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results.keys():\n",
    "    result = pd.DataFrame(data=results[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>2.519981e+00</td>\n",
       "      <td>5.748583e-02</td>\n",
       "      <td>4.635986</td>\n",
       "      <td>0.063348</td>\n",
       "      <td>0.482441</td>\n",
       "      <td>2.281545e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.780842e+00</td>\n",
       "      <td>8.990913e-02</td>\n",
       "      <td>6.449194</td>\n",
       "      <td>0.208345</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2.245328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>3.386065e-07</td>\n",
       "      <td>3.617094e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.626572e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.298805e+00</td>\n",
       "      <td>5.372440e-02</td>\n",
       "      <td>6.172554</td>\n",
       "      <td>0.175214</td>\n",
       "      <td>0.083781</td>\n",
       "      <td>8.716088e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>9.064189e-01</td>\n",
       "      <td>1.120850e-02</td>\n",
       "      <td>1.190058</td>\n",
       "      <td>0.016266</td>\n",
       "      <td>0.965870</td>\n",
       "      <td>2.097016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>5.407604e-01</td>\n",
       "      <td>2.358529e-02</td>\n",
       "      <td>0.876697</td>\n",
       "      <td>0.116868</td>\n",
       "      <td>0.981051</td>\n",
       "      <td>6.039177e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo      mae_mean       mae_std  rmse_mean  rmse_std   r2_mean  \\\n",
       "0  manual           NaN           NaN        NaN       NaN       NaN   \n",
       "1   ridge  2.519981e+00  5.748583e-02   4.635986  0.063348  0.482441   \n",
       "2   lasso  2.780842e+00  8.990913e-02   6.449194  0.208345  0.000071   \n",
       "3    cart  3.386065e-07  3.617094e-07   0.000005  0.000005  1.000000   \n",
       "4     svr  2.298805e+00  5.372440e-02   6.172554  0.175214  0.083781   \n",
       "5     xgb  9.064189e-01  1.120850e-02   1.190058  0.016266  0.965870   \n",
       "6      rf  5.407604e-01  2.358529e-02   0.876697  0.116868  0.981051   \n",
       "7     ann           NaN           NaN        NaN       NaN       NaN   \n",
       "\n",
       "         r2_std  \n",
       "0           NaN  \n",
       "1  2.281545e-02  \n",
       "2  2.245328e-04  \n",
       "3  1.626572e-12  \n",
       "4  8.716088e-03  \n",
       "5  2.097016e-03  \n",
       "6  6.039177e-03  \n",
       "7           NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results_train.keys():\n",
    "    result = pd.DataFrame(data=results_train[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2 - Variable Rechazo, Oxidacion y Origen-Contenedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml = df.loc[:,['ZonaPesca','EspecieMP','ModalidadLimpieza','TipoPesca', 'DiasFrigorifico',\n",
    "                              'Sal','Histamina',\n",
    "          'PesoMedio','MinutosPersonaKg','RtoLimpieza', 'Rechazos','Oxidacion','Carguero']]\n",
    "\n",
    "data_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results_train ={}\n",
    "modelos = ['manual', 'ridge','lasso','cart','svr','xgb','rf', 'ann']\n",
    "for modelo in modelos:\n",
    "    results[modelo]=[]\n",
    "    results_train[modelo]=[]\n",
    "\n",
    "\n",
    "items = [i for i in range(data_ml.shape[0])]\n",
    "for training, validation in k_fold_cross_validation(items, 10):\n",
    "    \n",
    "    # Preparamos los datos de entrada en los modelos\n",
    "    df_train = data_ml.ix[training]\n",
    "    df_validation = data_ml.ix[validation]\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATOS PARA ML\n",
    "    #######################################################\n",
    "    \n",
    "    df_train_dummies = pd.get_dummies(df_train).fillna(0)\n",
    "    df_validation_dummies = pd.get_dummies(df_validation).fillna(0)\n",
    "    \n",
    "    # checkear que tengan las mismas columnas\n",
    "    for column in df_train_dummies.columns:\n",
    "        if column not in df_validation_dummies:\n",
    "            df_validation_dummies[column]=0\n",
    "    \n",
    "    features_list = df_train_dummies.columns\n",
    "    \n",
    "    # Convertimos features y target en numpies\n",
    "    X_train = np.array(df_train_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    X_test = np.array(df_validation_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    y_train = np.array(df_train_dummies['RtoLimpieza'])\n",
    "    y_test = np.array(df_validation_dummies['RtoLimpieza'])\n",
    "    \n",
    "    # Normalizamos los predictores\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xscaler.fit(X_train)\n",
    "    X_train = Xscaler.transform(X_train)\n",
    "    X_test = Xscaler.transform(X_test)\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RIDGE REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    ridge = Ridge(normalize=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge.predict(X_test)\n",
    "    results['ridge'].append(get_error(y_test, y_pred_ridge))\n",
    "    results_train['ridge'].append(get_error(y_train, ridge.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### LASSO REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_lasso = lasso.predict(X_test)\n",
    "    results['lasso'].append(get_error(y_test, y_pred_lasso))\n",
    "    results_train['lasso'].append(get_error(y_train, lasso.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### CART\n",
    "    #######################################################\n",
    "    \n",
    "    cart = DecisionTreeRegressor()\n",
    "    cart.fit(X_train, y_train)\n",
    "    y_pred_cart = cart.predict(X_test)\n",
    "    results['cart'].append(get_error(y_test, y_pred_cart))\n",
    "    results_train['cart'].append(get_error(y_train, cart.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### SVC REGRESOR\n",
    "    #######################################################\n",
    "    \n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred_svr = svr.predict(X_test)\n",
    "    results['svr'].append(get_error(y_test, y_pred_svr))\n",
    "    results_train['svr'].append(get_error(y_train, svr.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### XGB\n",
    "    #######################################################\n",
    "    \n",
    "    xgb = GradientBoostingRegressor()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    results['xgb'].append(get_error(y_test, y_pred_xgb))\n",
    "    results_train['xgb'].append(get_error(y_train, xgb.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RANDOM FOREST\n",
    "    #######################################################\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    results['rf'].append(get_error(y_test, y_pred_rf))\n",
    "    results_train['rf'].append(get_error(y_train, rf.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATA PREP FOR ANN\n",
    "    #######################################################\n",
    "    \"\"\"\n",
    "    yscaler = MinMaxScaler()\n",
    "    yscaler.fit(y_train.reshape(-1,1))\n",
    "    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\n",
    "    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN - MODEL CONSTRUCTION\n",
    "    #######################################################\n",
    "    \n",
    "    annmodel = Sequential()\n",
    "    annmodel.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    annmodel.add(Dropout(0.2))\n",
    "    annmodel.add(Dense(25, activation='relu'))\n",
    "    annmodel.add(Dense(1, activation = \"sigmoid\"))\n",
    "    annmodel.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN\n",
    "    #######################################################\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \n",
    "          validation_data = (X_test, y_test_ann))\n",
    "    y_pred_ann = annmodel.predict(X_test)\n",
    "    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\n",
    "    results['ann'].append(get_error(y_test, y_pred_ann_desnorm))\n",
    "    \n",
    "    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\n",
    "    results_train['ann'].append(get_error(y_train, y_pred_ann_train))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>3.078949</td>\n",
       "      <td>0.595590</td>\n",
       "      <td>4.809704</td>\n",
       "      <td>1.129568</td>\n",
       "      <td>0.242801</td>\n",
       "      <td>0.504656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.781482</td>\n",
       "      <td>0.583450</td>\n",
       "      <td>6.162875</td>\n",
       "      <td>2.047277</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.025811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>1.413857</td>\n",
       "      <td>0.294046</td>\n",
       "      <td>2.239973</td>\n",
       "      <td>0.815805</td>\n",
       "      <td>0.653367</td>\n",
       "      <td>0.569762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.292800</td>\n",
       "      <td>0.564400</td>\n",
       "      <td>5.904009</td>\n",
       "      <td>2.097801</td>\n",
       "      <td>0.086386</td>\n",
       "      <td>0.055709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>1.056555</td>\n",
       "      <td>0.129669</td>\n",
       "      <td>1.608047</td>\n",
       "      <td>0.383889</td>\n",
       "      <td>0.857028</td>\n",
       "      <td>0.208642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>1.037363</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>1.708259</td>\n",
       "      <td>0.776506</td>\n",
       "      <td>0.818834</td>\n",
       "      <td>0.285992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mae_mean   mae_std  rmse_mean  rmse_std   r2_mean    r2_std\n",
       "0  manual       NaN       NaN        NaN       NaN       NaN       NaN\n",
       "1   ridge  3.078949  0.595590   4.809704  1.129568  0.242801  0.504656\n",
       "2   lasso  2.781482  0.583450   6.162875  2.047277 -0.018176  0.025811\n",
       "3    cart  1.413857  0.294046   2.239973  0.815805  0.653367  0.569762\n",
       "4     svr  2.292800  0.564400   5.904009  2.097801  0.086386  0.055709\n",
       "5     xgb  1.056555  0.129669   1.608047  0.383889  0.857028  0.208642\n",
       "6      rf  1.037363  0.172697   1.708259  0.776506  0.818834  0.285992\n",
       "7     ann       NaN       NaN        NaN       NaN       NaN       NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results.keys():\n",
    "    result = pd.DataFrame(data=results[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>2.394885</td>\n",
       "      <td>5.925209e-02</td>\n",
       "      <td>4.511971</td>\n",
       "      <td>0.059540</td>\n",
       "      <td>0.509761</td>\n",
       "      <td>2.145682e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.780842</td>\n",
       "      <td>8.990913e-02</td>\n",
       "      <td>6.449194</td>\n",
       "      <td>0.208345</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2.245328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.494237e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.924728e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.186805</td>\n",
       "      <td>5.577380e-02</td>\n",
       "      <td>6.191210</td>\n",
       "      <td>0.188084</td>\n",
       "      <td>0.078356</td>\n",
       "      <td>5.339998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.643618</td>\n",
       "      <td>7.793197e-03</td>\n",
       "      <td>0.884816</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.981108</td>\n",
       "      <td>1.532863e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.405159</td>\n",
       "      <td>1.381396e-02</td>\n",
       "      <td>0.669441</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>0.989194</td>\n",
       "      <td>1.165032e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mae_mean       mae_std  rmse_mean  rmse_std   r2_mean        r2_std\n",
       "0  manual       NaN           NaN        NaN       NaN       NaN           NaN\n",
       "1   ridge  2.394885  5.925209e-02   4.511971  0.059540  0.509761  2.145682e-02\n",
       "2   lasso  2.780842  8.990913e-02   6.449194  0.208345  0.000071  2.245328e-04\n",
       "3    cart  0.000001  7.494237e-07   0.000013  0.000006  1.000000  3.924728e-12\n",
       "4     svr  2.186805  5.577380e-02   6.191210  0.188084  0.078356  5.339998e-03\n",
       "5     xgb  0.643618  7.793197e-03   0.884816  0.014282  0.981108  1.532863e-03\n",
       "6      rf  0.405159  1.381396e-02   0.669441  0.040359  0.989194  1.165032e-03\n",
       "7     ann       NaN           NaN        NaN       NaN       NaN           NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results_train.keys():\n",
    "    result = pd.DataFrame(data=results_train[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 3 - Variable Rechazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 11)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml = df.loc[:,['ZonaPesca','EspecieMP','ModalidadLimpieza','TipoPesca', 'DiasFrigorifico',\n",
    "                              'Sal','Histamina',\n",
    "          'PesoMedio','MinutosPersonaKg','RtoLimpieza', 'Rechazos']]\n",
    "\n",
    "data_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results_train ={}\n",
    "modelos = ['manual', 'ridge','lasso','cart','svr','xgb','rf', 'ann']\n",
    "for modelo in modelos:\n",
    "    results[modelo]=[]\n",
    "    results_train[modelo]=[]\n",
    "\n",
    "\n",
    "items = [i for i in range(data_ml.shape[0])]\n",
    "for training, validation in k_fold_cross_validation(items, 10):\n",
    "    \n",
    "    # Preparamos los datos de entrada en los modelos\n",
    "    df_train = data_ml.ix[training]\n",
    "    df_validation = data_ml.ix[validation]\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATOS PARA ML\n",
    "    #######################################################\n",
    "    \n",
    "    df_train_dummies = pd.get_dummies(df_train).fillna(0)\n",
    "    df_validation_dummies = pd.get_dummies(df_validation).fillna(0)\n",
    "    \n",
    "    # checkear que tengan las mismas columnas\n",
    "    for column in df_train_dummies.columns:\n",
    "        if column not in df_validation_dummies:\n",
    "            df_validation_dummies[column]=0\n",
    "    \n",
    "    features_list = df_train_dummies.columns\n",
    "    \n",
    "    # Convertimos features y target en numpies\n",
    "    X_train = np.array(df_train_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    X_test = np.array(df_validation_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    y_train = np.array(df_train_dummies['RtoLimpieza'])\n",
    "    y_test = np.array(df_validation_dummies['RtoLimpieza'])\n",
    "    \n",
    "    # Normalizamos los predictores\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xscaler.fit(X_train)\n",
    "    X_train = Xscaler.transform(X_train)\n",
    "    X_test = Xscaler.transform(X_test)\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RIDGE REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    ridge = Ridge(normalize=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge.predict(X_test)\n",
    "    results['ridge'].append(get_error(y_test, y_pred_ridge))\n",
    "    results_train['ridge'].append(get_error(y_train, ridge.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### LASSO REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_lasso = lasso.predict(X_test)\n",
    "    results['lasso'].append(get_error(y_test, y_pred_lasso))\n",
    "    results_train['lasso'].append(get_error(y_train, lasso.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### CART\n",
    "    #######################################################\n",
    "    \n",
    "    cart = DecisionTreeRegressor()\n",
    "    cart.fit(X_train, y_train)\n",
    "    y_pred_cart = cart.predict(X_test)\n",
    "    results['cart'].append(get_error(y_test, y_pred_cart))\n",
    "    results_train['cart'].append(get_error(y_train, cart.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### SVC REGRESOR\n",
    "    #######################################################\n",
    "    \n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred_svr = svr.predict(X_test)\n",
    "    results['svr'].append(get_error(y_test, y_pred_svr))\n",
    "    results_train['svr'].append(get_error(y_train, svr.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### XGB\n",
    "    #######################################################\n",
    "    \n",
    "    xgb = GradientBoostingRegressor()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    results['xgb'].append(get_error(y_test, y_pred_xgb))\n",
    "    results_train['xgb'].append(get_error(y_train, xgb.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RANDOM FOREST\n",
    "    #######################################################\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    results['rf'].append(get_error(y_test, y_pred_rf))\n",
    "    results_train['rf'].append(get_error(y_train, rf.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATA PREP FOR ANN\n",
    "    #######################################################\n",
    "    \"\"\"\n",
    "    yscaler = MinMaxScaler()\n",
    "    yscaler.fit(y_train.reshape(-1,1))\n",
    "    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\n",
    "    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN - MODEL CONSTRUCTION\n",
    "    #######################################################\n",
    "    \n",
    "    annmodel = Sequential()\n",
    "    annmodel.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    annmodel.add(Dropout(0.2))\n",
    "    annmodel.add(Dense(25, activation='relu'))\n",
    "    annmodel.add(Dense(1, activation = \"sigmoid\"))\n",
    "    annmodel.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN\n",
    "    #######################################################\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \n",
    "          validation_data = (X_test, y_test_ann))\n",
    "    y_pred_ann = annmodel.predict(X_test)\n",
    "    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\n",
    "    results['ann'].append(get_error(y_test, y_pred_ann_desnorm))\n",
    "    \n",
    "    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\n",
    "    results_train['ann'].append(get_error(y_train, y_pred_ann_train))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>3.085272</td>\n",
       "      <td>0.572981</td>\n",
       "      <td>4.865852</td>\n",
       "      <td>1.136027</td>\n",
       "      <td>0.225035</td>\n",
       "      <td>0.515967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.781429</td>\n",
       "      <td>0.583474</td>\n",
       "      <td>6.162906</td>\n",
       "      <td>2.047244</td>\n",
       "      <td>-0.018191</td>\n",
       "      <td>0.025826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>1.451042</td>\n",
       "      <td>0.319605</td>\n",
       "      <td>2.268084</td>\n",
       "      <td>0.837359</td>\n",
       "      <td>0.617393</td>\n",
       "      <td>0.671338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.273794</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>5.897361</td>\n",
       "      <td>2.084910</td>\n",
       "      <td>0.085880</td>\n",
       "      <td>0.046455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>1.015021</td>\n",
       "      <td>0.127444</td>\n",
       "      <td>1.528596</td>\n",
       "      <td>0.322364</td>\n",
       "      <td>0.870502</td>\n",
       "      <td>0.195830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>1.037854</td>\n",
       "      <td>0.138027</td>\n",
       "      <td>1.607035</td>\n",
       "      <td>0.513944</td>\n",
       "      <td>0.852290</td>\n",
       "      <td>0.212720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mae_mean   mae_std  rmse_mean  rmse_std   r2_mean    r2_std\n",
       "0  manual       NaN       NaN        NaN       NaN       NaN       NaN\n",
       "1   ridge  3.085272  0.572981   4.865852  1.136027  0.225035  0.515967\n",
       "2   lasso  2.781429  0.583474   6.162906  2.047244 -0.018191  0.025826\n",
       "3    cart  1.451042  0.319605   2.268084  0.837359  0.617393  0.671338\n",
       "4     svr  2.273794  0.554045   5.897361  2.084910  0.085880  0.046455\n",
       "5     xgb  1.015021  0.127444   1.528596  0.322364  0.870502  0.195830\n",
       "6      rf  1.037854  0.138027   1.607035  0.513944  0.852290  0.212720\n",
       "7     ann       NaN       NaN        NaN       NaN       NaN       NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results.keys():\n",
    "    result = pd.DataFrame(data=results[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Oxidacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml = df.loc[:,['ZonaPesca','EspecieMP','ModalidadLimpieza','TipoPesca', 'DiasFrigorifico',\n",
    "                              'Sal','Histamina',\n",
    "          'PesoMedio','MinutosPersonaKg','RtoLimpieza', 'Oxidacion']]\n",
    "\n",
    "data_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\n    yscaler = MinMaxScaler()\\n    yscaler.fit(y_train.reshape(-1,1))\\n    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\\n    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\\n    \\n    #######################################################\\n    ###### ANN - MODEL CONSTRUCTION\\n    #######################################################\\n    \\n    annmodel = Sequential()\\n    annmodel.add(Dense(50, activation=\\'relu\\', input_shape=(X_train.shape[1],)))\\n    annmodel.add(Dropout(0.2))\\n    annmodel.add(Dense(25, activation=\\'relu\\'))\\n    annmodel.add(Dense(1, activation = \"sigmoid\"))\\n    annmodel.compile(loss=\\'mse\\', optimizer=\\'adam\\')\\n    \\n    #######################################################\\n    ###### ANN\\n    #######################################################\\n    \\n    # Entrenamos el modelo\\n    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \\n          validation_data = (X_test, y_test_ann))\\n    y_pred_ann = annmodel.predict(X_test)\\n    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\\n    results[\\'ann\\'].append(get_error(y_test, y_pred_ann_desnorm))\\n    \\n    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\\n    results_train[\\'ann\\'].append(get_error(y_train, y_pred_ann_train))\\n    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results_train ={}\n",
    "modelos = ['manual', 'ridge','lasso','cart','svr','xgb','rf', 'ann']\n",
    "for modelo in modelos:\n",
    "    results[modelo]=[]\n",
    "    results_train[modelo]=[]\n",
    "\n",
    "\n",
    "items = [i for i in range(data_ml.shape[0])]\n",
    "for training, validation in k_fold_cross_validation(items, 10):\n",
    "    \n",
    "    # Preparamos los datos de entrada en los modelos\n",
    "    df_train = data_ml.ix[training]\n",
    "    df_validation = data_ml.ix[validation]\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATOS PARA ML\n",
    "    #######################################################\n",
    "    \n",
    "    df_train_dummies = pd.get_dummies(df_train).fillna(0)\n",
    "    df_validation_dummies = pd.get_dummies(df_validation).fillna(0)\n",
    "    \n",
    "    # checkear que tengan las mismas columnas\n",
    "    for column in df_train_dummies.columns:\n",
    "        if column not in df_validation_dummies:\n",
    "            df_validation_dummies[column]=0\n",
    "    \n",
    "    features_list = df_train_dummies.columns\n",
    "    \n",
    "    # Convertimos features y target en numpies\n",
    "    X_train = np.array(df_train_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    X_test = np.array(df_validation_dummies.drop(columns=['RtoLimpieza'], axis= 1))\n",
    "    y_train = np.array(df_train_dummies['RtoLimpieza'])\n",
    "    y_test = np.array(df_validation_dummies['RtoLimpieza'])\n",
    "    \n",
    "    # Normalizamos los predictores\n",
    "    Xscaler = MinMaxScaler()\n",
    "    Xscaler.fit(X_train)\n",
    "    X_train = Xscaler.transform(X_train)\n",
    "    X_test = Xscaler.transform(X_test)\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RIDGE REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    ridge = Ridge(normalize=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred_ridge = ridge.predict(X_test)\n",
    "    results['ridge'].append(get_error(y_test, y_pred_ridge))\n",
    "    results_train['ridge'].append(get_error(y_train, ridge.predict(X_train)))\n",
    "    \n",
    "    def fit_model(model):\n",
    "        \n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### LASSO REGRESSION\n",
    "    #######################################################\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_lasso = lasso.predict(X_test)\n",
    "    results['lasso'].append(get_error(y_test, y_pred_lasso))\n",
    "    results_train['lasso'].append(get_error(y_train, lasso.predict(X_train)))\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    ###### CART\n",
    "    #######################################################\n",
    "    \n",
    "    cart = DecisionTreeRegressor()\n",
    "    cart.fit(X_train, y_train)\n",
    "    y_pred_cart = cart.predict(X_test)\n",
    "    results['cart'].append(get_error(y_test, y_pred_cart))\n",
    "    results_train['cart'].append(get_error(y_train, cart.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### SVC REGRESOR\n",
    "    #######################################################\n",
    "    \n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred_svr = svr.predict(X_test)\n",
    "    results['svr'].append(get_error(y_test, y_pred_svr))\n",
    "    results_train['svr'].append(get_error(y_train, svr.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### XGB\n",
    "    #######################################################\n",
    "    \n",
    "    xgb = GradientBoostingRegressor()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    results['xgb'].append(get_error(y_test, y_pred_xgb))\n",
    "    results_train['xgb'].append(get_error(y_train, xgb.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### RANDOM FOREST\n",
    "    #######################################################\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    results['rf'].append(get_error(y_test, y_pred_rf))\n",
    "    results_train['rf'].append(get_error(y_train, rf.predict(X_train)))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### DATA PREP FOR ANN\n",
    "    #######################################################\n",
    "    \"\"\"\n",
    "    yscaler = MinMaxScaler()\n",
    "    yscaler.fit(y_train.reshape(-1,1))\n",
    "    y_train_ann = yscaler.transform(y_train.reshape(-1,1))\n",
    "    y_test_ann = yscaler.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN - MODEL CONSTRUCTION\n",
    "    #######################################################\n",
    "    \n",
    "    annmodel = Sequential()\n",
    "    annmodel.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    annmodel.add(Dropout(0.2))\n",
    "    annmodel.add(Dense(25, activation='relu'))\n",
    "    annmodel.add(Dense(1, activation = \"sigmoid\"))\n",
    "    annmodel.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    #######################################################\n",
    "    ###### ANN\n",
    "    #######################################################\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    annmodel.fit(X_train, y_train_ann, epochs=10, verbose=0, \n",
    "          validation_data = (X_test, y_test_ann))\n",
    "    y_pred_ann = annmodel.predict(X_test)\n",
    "    y_pred_ann_desnorm = yscaler.inverse_transform(y_pred_ann)\n",
    "    results['ann'].append(get_error(y_test, y_pred_ann_desnorm))\n",
    "    \n",
    "    y_pred_ann_train = yscaler.inverse_transform(annmodel.predict(X_train))\n",
    "    results_train['ann'].append(get_error(y_train, y_pred_ann_train))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridge</td>\n",
       "      <td>3.112272</td>\n",
       "      <td>0.555634</td>\n",
       "      <td>4.831318</td>\n",
       "      <td>1.106512</td>\n",
       "      <td>0.236368</td>\n",
       "      <td>0.499454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso</td>\n",
       "      <td>2.781482</td>\n",
       "      <td>0.583450</td>\n",
       "      <td>6.162875</td>\n",
       "      <td>2.047277</td>\n",
       "      <td>-0.018176</td>\n",
       "      <td>0.025811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cart</td>\n",
       "      <td>1.840971</td>\n",
       "      <td>0.227376</td>\n",
       "      <td>2.727881</td>\n",
       "      <td>0.503353</td>\n",
       "      <td>0.624369</td>\n",
       "      <td>0.532205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svr</td>\n",
       "      <td>2.395113</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>5.899646</td>\n",
       "      <td>2.048665</td>\n",
       "      <td>0.082479</td>\n",
       "      <td>0.043938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>1.383459</td>\n",
       "      <td>0.169045</td>\n",
       "      <td>1.942688</td>\n",
       "      <td>0.300818</td>\n",
       "      <td>0.801752</td>\n",
       "      <td>0.286150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>1.442760</td>\n",
       "      <td>0.228531</td>\n",
       "      <td>2.102303</td>\n",
       "      <td>0.641385</td>\n",
       "      <td>0.765261</td>\n",
       "      <td>0.314335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mae_mean   mae_std  rmse_mean  rmse_std   r2_mean    r2_std\n",
       "0  manual       NaN       NaN        NaN       NaN       NaN       NaN\n",
       "1   ridge  3.112272  0.555634   4.831318  1.106512  0.236368  0.499454\n",
       "2   lasso  2.781482  0.583450   6.162875  2.047277 -0.018176  0.025811\n",
       "3    cart  1.840971  0.227376   2.727881  0.503353  0.624369  0.532205\n",
       "4     svr  2.395113  0.560500   5.899646  2.048665  0.082479  0.043938\n",
       "5     xgb  1.383459  0.169045   1.942688  0.300818  0.801752  0.286150\n",
       "6      rf  1.442760  0.228531   2.102303  0.641385  0.765261  0.314335\n",
       "7     ann       NaN       NaN        NaN       NaN       NaN       NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results =[]\n",
    "for key in results.keys():\n",
    "    result = pd.DataFrame(data=results[key], columns=['mae','rmse','r2'])\n",
    "    df_results.append([key, result.mae.mean(),result.mae.std(),\n",
    "                      result.rmse.mean(),result.rmse.std(),\n",
    "                    result.r2.mean(),result.r2.std()])\n",
    "    \n",
    "df_results = pd.DataFrame(data=df_results, columns = ['modelo','mae_mean', 'mae_std',\n",
    "                                                      'rmse_mean','rmse_std', 'r2_mean','r2_std'])\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
